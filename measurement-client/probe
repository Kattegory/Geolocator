#! /usr/bin/env python

from __future__ import division

import argparse
import collections
import contextlib
import ctypes
import datetime
import errno
import itertools
import json
import mmap
import os
import random
import resource
import socket
import struct
import subprocess
import sys
import time

if not hasattr(resource, "RLIMIT_NOFILE"):
    if hasattr(resource, "RLIMIT_OFILE"):
        setattr(resource, "RLIMIT_NOFILE", getattr(resource, "RLIMIT_OFILE"))
    else:
        raise EnvironmentError(
            "don't know how to access the limit on the number of open files")

try:
    import configparser
except ImportError:
    import ConfigParser as configparser

try:
    from urllib.error import URLError
    from urllib.request import urlopen
    from urllib.parse import urlencode, urlsplit, urljoin
except ImportError:
    from urllib2 import URLError
    from urllib2 import urlopen as _urlopen
    def urlopen(*a, **k):
        return contextlib.closing(_urlopen(*a, **k))
    from urllib import urlencode
    from urlparse import urlsplit, urljoin

# We have problems with DNS resolution failing for the reports server,
# possibly wasting hours of effort, so we monkey-patch
# socket.getaddrinfo to add a cache, and we preload the addresses for
# the reports server's URLs.  Preloading is retried at 5-second intervals
# for one minute before we give up.
dns_cache = {}
real_getaddrinfo = socket.getaddrinfo
def caching_getaddrinfo(*args):
    global dns_cache
    try:
        return dns_cache[args]
    except KeyError:
        res = real_getaddrinfo(*args)
        dns_cache[args] = res
        return res
socket.getaddrinfo = caching_getaddrinfo

def warm_dns_cache_1(*args):
    global dns_cache
    if args in dns_cache: return
    retries = 0
    sys.stderr.write("Looking up {}:{}...".format(args[0], args[1]))
    sys.stderr.flush()
    while True:
        try:
            dns_cache[args] = real_getaddrinfo(*args)
            sys.stderr.write("ok\n")
            return
        except socket.gaierror as e:
            if e.errno != socket.EAI_NONAME:
                raise
            if retries == 12:
                raise
            retries += 1
            sys.stderr.write("NXDOMAIN\nretrying in 5s...")
            sys.stderr.flush()
            time.sleep(5)

def warm_dns_cache(cfg):
    for url in (cfg.lm_coarse_url, cfg.lm_fine_url, cfg.results_url):
        s = urlsplit(url)
        if s.scheme == 'https':
            warm_dns_cache_1(s.hostname, s.port or 443, 0, 1)
        elif s.scheme == 'http':
            warm_dns_cache_1(s.hostname, s.port or 80, 0, 1)
        else:
            raise ValueError("don't know how to warm DNS cache for {}"
                             .format(url))

# Communication with probe-core uses a shared memory segment, passed down
# as the "stdin".  Unfortunately, the stdlib doesn't expose shm_open.
def find_shm_open():
    # shm_open and shm_unlink might be in one of several different libraries.
    libs_to_search = [
        "libc.so.6", "libc.so.1", "librt.so.1", "libSystem.B.dylib",
    ]
    for lib in libs_to_search:
        try:
            h = ctypes.CDLL(lib, use_errno=True)
            shm_open = h.shm_open
            shm_unlink = h.shm_unlink

            # The last argument to shm_open is mode_t, but ctypes doesn't
            # expose mode_t.  The integer promotions will hopefully
            # prevent problems.
            shm_open.argtypes = (ctypes.c_char_p, ctypes.c_int, ctypes.c_int)
            shm_unlink.argtypes = (ctypes.c_char_p,)
            return (shm_open, shm_unlink)

        except:
            continue

    return (None, None)

shm_open, shm_unlink = find_shm_open()
if shm_open is not None:
    try:
        from tempfile import _RandomNameSequence
    except:
        def _RandomNameSequence():
            """_RandomNameSequence generates an endless sequence of
               unpredictable strings which can safely be incorporated
               into file names.  Each string is six characters long.
            """
            characters = ("abcdefghijklmnopqrstuvwxyz"
                          "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
                          "0123456789_")
            rng = random.Random()
            normcase = os.path.normcase
            while 1:
                letters = []
                yield normcase("".join(
                    rng.choice(characters) for _ in "123456"
                ))

    class MemorySegment:
        def __init__(self):
            self._fd = -1

            retries = 0
            flags = os.O_RDWR|os.O_CREAT|os.O_EXCL
            mode = 384 # 0600
            for nm in _RandomNameSequence():
                xnm = "/"+nm
                exnm = xnm.encode("utf-8")
                fd = shm_open(exnm, flags, mode)
                if fd >= 0:
                    break
                err = ctypes.get_errno()
                if err != errno.EEXIST or retries > 1000:
                    raise OSError(err, "shm_open: " + os.strerror(err), xnm)
                retries += 1

            self._fd = fd

            rv = shm_unlink(exnm)
            if rv:
                err = ctypes.get_errno()
                os.close(self._fd)
                self._fd = -1
                raise OSError(err, "shm_unlink: " + os.strerror(err), xnm)

        def __enter__(self):
            return self

        def __exit__(self, *ignored):
            self.close()
            return False

        def __del__(self):
            self.close()

        def close(self):
            if self._fd != -1:
                fd = self._fd
                self._fd = -1
                os.close(fd)

        def fileno(self):
            return self._fd

else:
    # if we don't have shm_open, a temporary file will do
    from tempfile import TemporaryFile as MemorySegment

AddrTuple = collections.namedtuple("AddrTuple",
                                   ("host", "port",
                                    "lat", "lon",
                                    "cbg_m", "cbg_b"))

class ConnBuffer:
    def __init__(self, addrs, spacing, timeout):
        self.addrs   = addrs
        self.n_conn  = len(addrs)
        self.n_proc  = 0
        self.spacing = spacing
        self.timeout = timeout
        self.hform   = struct.Struct("=IIIIII")
        self.cform   = struct.Struct("=I4sHHI")
        self.seg_obj = None
        self.seg_fd  = None
        self.seg_map = None
        self.seg_len = self.hform.size + self.cform.size * self.n_conn

    def __enter__(self):
        self.seg_obj = MemorySegment()
        self.seg_fd  = self.seg_obj.fileno()
        os.ftruncate(self.seg_fd, self.seg_len)
        self.seg_map = mmap.mmap(self.seg_fd, self.seg_len)
        self.encode_addrs()
        return self

    def __del__(self):
        self.close()

    def __exit__(self, *ignored):
        self.close()
        return False

    def close(self):
        if self.seg_map is not None:
            self.seg_map.close()
            self.seg_map = None
        if self.seg_obj is not None:
            self.seg_obj.close()
            self.seg_obj = None
            self.seg_fd = -1

    def check_completion(self):
        _,_,n_proc,_,_,_ = self.hform.unpack(self.seg_map[0:self.hform.size])
        self.n_proc = n_proc
        return self.n_proc == self.n_conn

    def encode_addrs(self):
        # Assign a serial number to each IP address.  This is only
        # used internally by probe-core, but it's much easier to
        # generate them in Python.
        serial = {}
        sno = 0
        for addr in self.addrs:
            if addr.host not in serial:
                serial[addr.host] = sno
                sno += 1

        self.hform.pack_into(self.seg_map, 0,
                             len(serial), self.n_conn, 0,
                             max(int(self.spacing * 1e6), 1000000),
                             max(int(self.timeout * 1e6), 1000000),
                             0)

        offset = self.hform.size
        for addr in self.addrs:
            ip = socket.inet_aton(addr.host)
            port = socket.htons(addr.port)
            self.cform.pack_into(self.seg_map, offset,
                                 serial[addr.host], ip, port, 0, 0)
            offset += self.cform.size

    def decode_results(self):
        offset = self.hform.size
        results = []
        while offset < self.seg_len:
            _, addr, port, err, elapsed = \
                self.cform.unpack_from(self.seg_map, offset)
            host = socket.inet_ntoa(addr)
            port = socket.ntohs(port)
            results.append((
                host, port,
                errno.errorcode.get(err, err),
                elapsed * 1e-6
            ))
            offset += self.cform.size

        return results

def report_results(cfg, results, coarse_circles):
    data = dict(vars(cfg))
    # We don't need to report all of the configuration parameters.
    del data["lm_coarse_url"]
    del data["lm_fine_url"]
    del data["server_url"]
    del data["results_url"]
    del data["config"]
    del data["core"]
    del data["no_report"]
    if data["location_unknown"]:
        del data["latitude"]
        del data["longitude"]
    else:
        del data["location_unknown"]

    if data["proxied_connection"]:
        if data["proxy_location_unknown"]:
            del data["proxy_latitude"]
            del data["proxy_longitude"]
        else:
            del data["proxy_location_unknown"]
    else:
        del data["proxy_latitude"]
        del data["proxy_longitude"]
        del data["proxy_location_unknown"]

    data["results"] = results
    data["circles"] = coarse_circles
    now = datetime.datetime.utcnow()
    data["timestamp"] = now.isoformat()
    blob = json.dumps(data, separators=(',', ':')).encode('utf-8')

    # Save the data to a file in the current directory.
    tmpl = now.strftime("probe-result-%Y-%m-%d-{:03d}.json")
    for i in range(1000):
        try:
            # O_EXCL is not accessible via plain open() in py2.
            fd = os.open(tmpl.format(i), os.O_WRONLY|os.O_CREAT|os.O_EXCL)
            with os.fdopen(fd, "wb") as f:
                f.write(blob)
                f.write(b"\n")
            break

        except OSError as e:
            if e.errno == errno.EEXIST:
                continue
            sys.stderr.write(
                "Unable to record data locally ({}: {}); continuing.\n"
                .format(e.filename, e.strerror))
            break
    else:
        sys.stderr.write(
            "Unable to record data locally (too many local records already); "
            "continuing.\n")

    if cfg.no_report:
        return

    # Push the data to the server.
    try:
        sys.stderr.write("Reporting results to server...")
        postdata = urlencode([('blob', blob)]).encode('utf-8')
        with urlopen(cfg.results_url, postdata) as f:
            # The expected response is either code 204 and no output,
            # or 200 and a small JSON confirmation.
            code = f.getcode()
            body = f.read()
    except URLError as e:
        sys.stderr.write("\n{}:\n   {}\n".format(cfg.landmark_url, e))
        try:
            sys.stderr.write("   reason: {}\n".format(e.reason))
            sys.stderr.write("   body:\n")
            sys.stderr.write(e.read())
            sys.stderr.write("\n")
        except Exception as ee:
            sys.stderr.write("   (dumping details failed: {})\n"
                             .format(ee))
            pass
        sys.exit(1)

    if code == 204 and body == b"":
        finished_message(None)
        return

    elif code == 200 and body != b"":
        try:
            resp = json.loads(body.decode("utf-8"))
            finished_message(resp["ccode"])
            return

        except Exception:
            pass

    sys.stderr.write(
        "unexpected response to POST {}:\n"
        "  code    = {}\n"
        "  headers = {!r}\n"
        "  body    = {!r}\n"
        .format(cfg.results_url, code, f.info().items(), body))
    sys.exit(1)

def finished_message(ccode):
    if ccode:
        sys.stderr.write("done (confirmation code: {}).".format(ccode))
    else:
        sys.stderr.write("done.")

    sys.stderr.write("\nThank you for your assistance.\n")

def perform_probes(cfg, landmarks):
    """Make a connection to each of the LANDMARKS, in order, and measure
       the time for connect(2) to either succeed or fail -- we don't
       care which.
    """
    addresses = choose_probe_order(cfg, landmarks)

    with ConnBuffer(addresses, cfg.spacing, cfg.timeout) as cb:

        cmd = [cfg.core]
        if cfg.socks5:
            cmd.append(cfg.socks5[0])
            cmd.append(str(cfg.socks5[1]))

        resource.setrlimit(resource.RLIMIT_NOFILE,
                           (min(len(landmarks), cfg.parallel) + 3,
                            cfg.max_parallel))
        cycles = 0
        while cycles < 5:
            if cycles == 0:
                sys.stderr.write("Performing {} RTT measurements...\n"
                                 .format(cb.n_conn))
            else:
                sys.stderr.write("{} measurements still to do, retrying...\n"
                                 .format(cb.n_conn - cb.n_proc))

            rc = subprocess.call(cmd, stdin=cb.seg_fd)
            if rc > 0:
                sys.stderr.write("'{}': unsuccessful exit, code {}\n"
                                 .format(" ".join(cmd), rc))

            elif rc < 0:
                sys.stderr.write("'{}': killed by signal {}\n"
                                 .format(" ".join(cmd), -rc))

            cycles += 1
            if cb.check_completion(): break

        else:
            sys.stderr.write(
                "Giving up after {} cycles with only {} of {} complete.\n"
                .format(cycles, cb.n_proc, cb.n_conn))

        return cb.decode_results()

def choose_probe_order(cfg, addresses):
    """Choose a randomized probe order for the ADDRESSES.  This both
       expands the list to include CFG.n_probes copies of each address,
       and shuffles it.
    """

    # We probe each host all at once, but we do them in a random order.
    # However, if one of the addresses has no location, we need to do
    # that one first, because it's the local address and we will use
    # that to estimate overhead.
    no_loc = []
    with_loc = []
    for addr in addresses:
        if abs(addr.lat) < 0.5 and abs(addr.lon) < 0.5:
            no_loc.append(addr)
        else:
            with_loc.append(addr)

    random.shuffle(no_loc)
    random.shuffle(with_loc)

    rv = []
    for addr in itertools.chain(no_loc, with_loc):
        for _ in range(cfg.n_probes):
            rv.append(addr)

    return rv

def compute_coarse_circles(cfg, landmarks, results):
    # Get the minimum RTT to each landmark.
    rtt_by_addr = collections.defaultdict(list)
    for r in results:
        rtt_by_addr[r[0]].append(r[3])
    minrtt_by_addr = { a: min(v) for a,v in rtt_by_addr.items() }

    probe_overhead = 0
    for lm in landmarks:
        if (abs(lm.lat) < 0.5 and abs(lm.lat) < 0.5
            and 0 < minrtt_by_addr[lm.host] < cfg.overhead_limit):
            probe_overhead = max(probe_overhead, minrtt_by_addr[lm.host])

    setattr(cfg, "overhead", probe_overhead)

    # The factor of 2 converts round-trip time to one-way distance.
    # The factor of 1000 converts km/ms to m/ms.
    cbg_m = cfg.cbg_coarse_speed * 1000 / 2
    cbg_b = -cfg.cbg_coarse_delay * cbg_m

    circles = []
    for lm in landmarks:
        if abs(lm.lat) < 0.5 and abs(lm.lon) < 0.5:
            continue
        minrtt = minrtt_by_addr[lm.host]
        if minrtt > cfg.cbg_time_limit:
            continue
        radius = cbg_m * (minrtt - probe_overhead) + cbg_b
        if not (0 < radius < cfg.cbg_dist_limit):
            continue
        # The server wants the radius in km.
        circles.append((lm.lat, lm.lon, radius/1000))

    circles.sort(key=lambda x: (x[2], x[0], x[1]))
    return circles


def validate_landmark_list(landmarks):
    def v1(item):
        try:
            if len(item) != 6:
                raise ValueError("wrong length")
            r_host, r_port = socket.getaddrinfo(
                item[0], item[1],
                socket.AF_INET, socket.SOCK_STREAM, 0, 0)[0][4]
            return AddrTuple(
                r_host, r_port,
                item[2], item[3], item[4], item[5])

        except Exception as e:
            if (isinstance(e, socket.gaierror) and
                e.args[0] == socket.EAI_ADDRFAMILY):
                return None

            raise type(e)("validating landmark list: item {!r}: {}"
                          .format(item, e))

    if not isinstance(landmarks, list):
        raise TypeError("landmark list was not a list, but {!r}"
                        .format(landmarks))

    return [addr for addr in (v1(item) for item in landmarks)
            if addr is not None]

def get_landmark_list(cfg, circles=None):
    """Read addresses to probe from the server."""
    try:
        if circles is None:
            sys.stderr.write("Retrieving continent-level landmarks...")
            landmark_url = cfg.lm_coarse_url
        else:
            sys.stderr.write("Retrieving second stage landmarks...")
            landmark_url = cfg.lm_fine_url
            landmark_url += '?n={}&'.format(cfg.n_fine_landmarks)
            landmark_url += '&'.join(
                urlencode([('lat', format(x[0], "6f")),
                           ('lon', format(x[1], "6f")),
                           ('rad', format(x[2], "3f"))])
                for x in circles)

        sys.stderr.flush()
        with urlopen(landmark_url) as f:
            landmarks = validate_landmark_list(
                json.loads(f.read().decode("utf-8")))
            sys.stderr.write("ok, {} landmarks\n".format(len(landmarks)))
            return landmarks

    except (URLError, TypeError, ValueError, UnicodeError) as e:
        sys.stderr.write("\n{}:\n   {}\n".format(landmark_url, e))
        sys.exit(1)

def parse_local_config_file(args):
    """Read the local config file, which tells us where to contact the
       server and specifies probe parameters.  For convenience,
       everything we get out of the config file is merged into the
       same attribute bag as the command line arguments.
    """
    try:
        with open(args.config) as f:
            p = configparser.RawConfigParser()
            p.readfp(f)

            getstr = lambda p, k: p.get("probe", k)
            getint = lambda p, k: p.getint("probe", k)
            getfloat = lambda p, k: p.getfloat("probe", k)
            geturl = lambda p, k: urljoin(args.server_url, p.get("probe", k))

            config_keys = [
                ("server_url", getstr),
                ("lm_coarse_url", geturl),
                ("lm_fine_url", geturl),
                ("results_url", geturl),
                ("spacing", getfloat),
                ("parallel", getint),
                ("timeout", getfloat),
                ("n_probes", getint),
                ("n_fine_landmarks", getint),
                ("cbg_dist_limit", getfloat),
                ("cbg_time_limit", getfloat),
                ("cbg_coarse_speed", getfloat),
                ("cbg_coarse_delay", getfloat),
                ("overhead_limit", getfloat),
            ]
            for k, getter in config_keys:
                setattr(args, k, getter(p, k))


            # Fewer than one connection at a time obviously doesn't
            # work.  The upper limit is the kernel-imposed limit on
            # open files per process, minus 3.
            max_parallel = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
            setattr(args, "max_parallel", max_parallel)
            if args.parallel == 0 or args.parallel > max_parallel:
                args.parallel = max_parallel
            elif args.parallel < 0:
                raise ValueError("'parallel' must be nonnegative")

            # poll(2) takes its timeout in milliseconds, so a timeout
            # smaller than one millisecond is impossible (probe-core
            # *could* be using ppoll, but we don't know that).  We
            # impose an artificial upper limit here of one minute.
            if args.timeout < 1 or args.timeout > 60000:
                raise ValueError("'timeout' must be from 1 to 60000")

            # spacings smaller than one millisecond are impossible for the
            # same reason as above, and it doesn't make sense for the spacing
            # to be bigger than the timeout.
            if args.spacing < 1 or args.spacing > args.timeout:
                raise ValueError("'spacing' must be from 1 to timeout")

            # Less than one probe per landmark doesn't make sense, and more
            # than 20 is unlikely to be helpful.
            if args.n_probes < 1 or args.n_probes > 20:
                raise ValueError("'n_probes' must be from 1 to 20")

            return args

    except (configparser.Error, ValueError) as e:
        sys.stderr.write("{}: parse error: {}\n".format(args.config, e))
        sys.exit(1)

    except OSError as e:
        sys.stderr.write("{}: {}\n".format(args.config, e.strerror))
        sys.exit(1)

def parse_command_line():
    ap = argparse.ArgumentParser(
        description="Make round-trip time measurements."
    )

    ap.add_argument("-c", "--config",
                    help="Local configuration file (default: probe.cf)")
    ap.add_argument("-C", "--core",
                    help="Measurement core executable (default: probe-core)")

    ap.add_argument("--latitude", type=float, metavar="LAT",
                    help="Latitude of this computer (decimal degrees)")
    ap.add_argument("--longitude", type=float, metavar="LON",
                    help="Longitude of this computer (decimal degrees)")
    ap.add_argument("--location-unknown", action="store_true",
                    help="Location of this computer is unknown")

    ap.add_argument("--proxy-latitude", type=float, metavar="LAT",
                    help="Latitude of the network proxy (decimal degrees)")
    ap.add_argument("--proxy-longitude", type=float, metavar="LON",
                    help="Longitude of the network proxy (decimal degrees)")
    ap.add_argument("--proxy-location-unknown", action="store_true",
                    help="Location of the network proxy is unknown")
    ap.add_argument("--proxy-label", metavar="LABEL",
                    help="Identifying label for the proxy.")

    ap.add_argument("--socks5", metavar="ADDR:PORT",
                    help="Address of a SOCKSv5 proxy to use.")

    ap.add_argument("--no-publication", action="store_true",
                    help="If the database is ever published, don't include "
                    "these measurements.")
    ap.add_argument("--no-report", action="store_true",
                    help="Do not report these results to the database, "
                    "just record them locally.")

    args = ap.parse_args()
    if ((not args.location_unknown
         and (args.latitude is None or args.longitude is None))
        or (args.location_unknown
            and (args.latitude is not None or args.longitude is not None))):
        ap.error("must specify both --latitude and --longitude, "
                 "or else --location-unknown")
    if (not args.proxy_location_unknown
        and args.proxy_latitude is None
        and args.proxy_longitude is None):
        setattr(args, "proxied_connection", False)
    else:
        setattr(args, "proxied_connection", True)
        if ((not args.proxy_location_unknown
             and (args.proxy_latitude is None or args.proxy_longitude is None))
            or (args.proxy_location_unknown
                and (args.proxy_latitude is not None
                     or args.proxy_longitude is not None))):
            ap.error("must specify both --proxy-latitude and "
                     "--proxy-longitude, or else --proxy-location-unknown")

    if args.socks5:
        try:
            host, port = args.socks5.split(":")
            args.socks5 = socket.getaddrinfo(
                host, port,
                socket.AF_UNSPEC, socket.SOCK_STREAM)[0][4]
        except Exception as e:
            ap.error("invalid --socks5 argument: " + str(e))

    thisdir = os.path.dirname(os.path.abspath(__file__))
    if args.core is None:
        if args.socks5:
            args.core = os.path.join(thisdir, "probe-core-socks")
        else:
            args.core = os.path.join(thisdir, "probe-core-direct")
    if args.config is None:
        args.config = os.path.join(thisdir, "probe.cf")

    return args

def main():
    args = parse_command_line()
    cfg = parse_local_config_file(args)
    warm_dns_cache(cfg)
    coarse_landmarks = get_landmark_list(cfg)
    coarse_results = perform_probes(cfg, coarse_landmarks)
    coarse_circles = compute_coarse_circles(cfg, coarse_landmarks,
                                            coarse_results)

    fine_landmarks = get_landmark_list(cfg, circles=coarse_circles)
    fine_results = perform_probes(cfg, fine_landmarks)

    # Stuff the total number of landmarks into the 'cfg' object in
    # order to report it to the server (which will log it
    # independently of the list of observations).
    setattr(cfg, "n_landmarks", len(coarse_landmarks) + len(fine_landmarks))

    fine_results.extend(coarse_results)
    report_results(cfg, fine_results, coarse_circles)

main()
